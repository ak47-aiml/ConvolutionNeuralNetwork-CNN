{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='steelblue'>\n",
    "\n",
    "## MNIST Digit Recognition  \n",
    "### From the Keras datasets, import the MNIST Digits data\n",
    "#### There are images of digits 0 to 9 and have labels associated with each image<br>\n",
    "<font size = \"3\">\n",
    "\n",
    "**Following examples are included in the processing:**\n",
    "\n",
    "- Check the version of `Tensorflow and Keras`\n",
    "- Load `training and test` data including labels\n",
    "- `Normalize` the images\n",
    "- `Plot few images` after being normalized\n",
    "- Create a `Neural Network` and build a model\n",
    "- `Train the model` on the training dataset\n",
    "- Evaluate the `accuracy of the model` using test dataset\n",
    "- `Plot the accuracy and loss` for the model\n",
    "</font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure tensorflow is properly installed\n",
    "tf.__version__, tf.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_mnist = keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "                                digits_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size: train images {}, train labels {}\".format(train_images.shape, \n",
    "                                                      train_labels.shape))\n",
    "\n",
    "# save the number of items in training dataset\n",
    "train_rows = train_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size: test images {}, test labels {}\".format(test_images.shape, \n",
    "                                                      test_labels.shape))\n",
    "\n",
    "# save the number of items in test dataset\n",
    "test_rows = test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at first 10 labels in training set\n",
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure\n",
    "plt.imshow(train_images[5], cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view 25 of the grayscale images\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)    # print 5 images per row\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the values to be between 0 and 1; min-max normalization\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot few normalized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view 25 of the grayscale images\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)    # print 5 images per row\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the image shape (horizontal pixels x vertical pixels x grey scale)\n",
    "iShape = (28,28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data needs to be reshaped.\n",
    "# The first convolution expects a single tensor containing everything, \n",
    "# so instead of 60,000 28x28x1 items in an array (60000, 28, 28), \n",
    "# it wants a single 4D array/tensor that is 60000x28x28x1, otherwise you will get an error.\n",
    "\n",
    "train_images = train_images.reshape(train_rows, 28, 28, 1)\n",
    "\n",
    "# reshape test images into a single tensor\n",
    "test_images = test_images.reshape(test_rows, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Convolution Neural Network - adding layers\n",
    "\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(64, activation = 'relu', input_shape = iShape, \n",
    "                        kernel_size=(3, 3), padding = 'same'))\n",
    "\n",
    "# (2,2) - pooling filter\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))          # (2,2) - pooling size\n",
    "\n",
    "# (3,3) - filter size, 64 number of filters\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'valid'))   \n",
    "\n",
    "# (2,2) - pooling filter\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))          # (2,2) - pooling size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid over fitting on training dataset, randomly drop neurons and their connections\n",
    "# remove 20% of them\n",
    "model.add(layers.Dropout(rate = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the previous layer into 1 dimensional array (flatten it)\n",
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once weâ€™ve flattened the data into a 1D array, add a dense hidden layer, which is normal \n",
    "# to a traditional neural network. Next, add another dropout layer before \n",
    "# adding a final dense layer which classifies the data\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "#model.add(layers.Dropout(0.2))\n",
    "\n",
    "# output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))   # helps classify into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with chosen parameters\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary\n",
    "<h3>\n",
    "    <ul>\n",
    "        <li>Shows all parameters and shape for each of the layers</li>\n",
    "        <li>Trainable params: is total number of parameters in our model</li>\n",
    "        <li>Non-trainable params: are parameters that cannot be used by model for training</li>\n",
    "    </ul>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Convolutional Neural Network (CNN)\n",
    "<h3><b>Used 10 epochs and got about 99.08% accuracy on training and the validation set</b></h3>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To measure time required to train\n",
    "import timeit, time\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the model and include a validation set (composed of 10% of the dataset)\n",
    "# Capturing the returned history enables you to plot the change in \n",
    "# error/loss and accuracy over time\n",
    "\n",
    "# takes about 10 minutes \n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "batches = 1000\n",
    "epochs = 6\n",
    "history = model.fit(train_images, train_labels, validation_split = 0.1, \n",
    "                    batch_size = batches, epochs = epochs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "exectime = time.strftime(\"%M:%S\", time.gmtime(execution_time)) \n",
    "print(\"To train it took: {} mins\".format(exectime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = model.metrics_names\n",
    "metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the test images to evaluate the model on a set of unseen images\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string1, string2):\n",
    "    # 2 rows 1 column\n",
    "    plt.subplots(2, 1, sharex=False, sharey=False, figsize=(8,6))\n",
    "    # plot 1\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history[string1])\n",
    "    plt.plot(history.history['val_'+string1])\n",
    "    plt.ylabel(string1)\n",
    "    plt.legend([string1, 'val_'+string1]);\n",
    "    \n",
    "    # plot 2\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history[string2])\n",
    "    plt.plot(history.history['val_'+string2])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string2)\n",
    "    plt.legend([string2, 'val_'+string2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, metrics_names[0], metrics_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds currently has the probability for each of the 10000 test images\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# get the prediction for each image\n",
    "preds = np.argmax(preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 10 predictions\n",
    "fig, axes = plt.subplots(ncols=10, sharex=False,\n",
    "                         sharey=True, figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    axes[i].set_title(preds[i])\n",
    "    axes[i].imshow(test_images[i], cmap='gray')\n",
    "    axes[i].get_xaxis().set_visible(False)\n",
    "    axes[i].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of correct predictions: {}\".format(len(preds[preds == test_labels])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of incorrect predictions: {}\".format(len(preds[preds != test_labels])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (8,6))\n",
    "sn.heatmap(cm, annot=True, cmap=plt.cm.Blues, fmt = 'g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, sharex=False,\n",
    "                         sharey=True, figsize=(20, 4))\n",
    "count = 0\n",
    "for i in range(10000):\n",
    "    if preds[i] != test_labels[i]:\n",
    "        axes[count].set_title(preds[i])\n",
    "        axes[count].imshow(test_images[i], cmap='gray')\n",
    "        axes[count].get_xaxis().set_visible(False)\n",
    "        axes[count].get_yaxis().set_visible(False)\n",
    "        count = count + 1\n",
    "        if count == 10:\n",
    "            break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Comic sans MS; font-size:1.4em;\">\n",
    "<font color='tomato'>\n",
    "    <h2>Practice</h2>\n",
    "    <h3>Try out different parameters and see how model accuracy changes</h3>\n",
    "    <ol>\n",
    "        <li>Play with different epoch values (10, 20, ...)</li>\n",
    "        <li>Add more Conv2D and Pooling layers</li>\n",
    "        <li>Change number of neuron in each dense layer</li>\n",
    "        <li>Change the batch size and see what happens</li>    \n",
    "    </ol>\n",
    "</font>\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
